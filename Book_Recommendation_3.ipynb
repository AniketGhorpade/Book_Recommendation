{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AniketGhorpade/Book_Recommendation/blob/main/Book_Recommendation_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - \n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Unsupervised\n",
        "##### **Contribution**    - Individual\n",
        "##### **Team Member 1** - Aniket K. Ghorpade"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the summary here within 500-600 words."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/AniketGhorpade/Book_Recommendation"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**During the last few decades, with the rise of Amazon,YouTube,Netflix and many other such web services, recommend-er systems have taken more and more place in our lives. From e-commerece (suggest to buyers articles that could interest them) to online advertisement(suggest to users the right contents matching there preferences), recommender systems are today unavoidable in our daily online journeys.\n",
        "  In a very genral way, recommender systems are algorithms aimed at suggesting relevant.\n",
        "  Items to users(Items being movies to watch, text to read, products to buy or anything else in the industries.) Recommender systems are really critical in some industries as they can genrate a huge amount of income when they are efficient or also be a way to stand out significantly from competitiors. The main objective is to create a book recommendation system for users.**"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "_uKY3ic1EQ6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "from scipy import stats\n",
        "\n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns \n",
        "from matplotlib import colors\n",
        "from matplotlib.ticker import PercentFormatter\n",
        "\n",
        "import warnings \n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import missingno as msno\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "\n",
        "books = pd.read_csv('/content/drive/MyDrive/Capstone Projects Submission/4. Unsupervised ML/Book Recommendation/Books.csv')\n",
        "ratings = pd.read_csv('/content/drive/MyDrive/Capstone Projects Submission/4. Unsupervised ML/Book Recommendation/Ratings.csv')\n",
        "users =  pd.read_csv('/content/drive/MyDrive/Capstone Projects Submission/4. Unsupervised ML/Book Recommendation/Users.csv') "
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "books.head(3)"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings.head(3) "
      ],
      "metadata": {
        "id": "VyrJa8okF9Ol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users.head(3)"
      ],
      "metadata": {
        "id": "a-t8gT-bGBUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [books,ratings,users]"
      ],
      "metadata": {
        "id": "l0zwGvOGG288"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "for i in data:\n",
        "  print(i.shape)"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "books.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings.info()"
      ],
      "metadata": {
        "id": "nJPf30LwIDSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users.info()"
      ],
      "metadata": {
        "id": "-9e4HC_bIH1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "books[books.duplicated()]"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users[users.duplicated()]"
      ],
      "metadata": {
        "id": "1ae75u0gIglk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings[ratings.duplicated()] "
      ],
      "metadata": {
        "id": "qB7HbylSIlnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "No any duplicate value is present in the dataset."
      ],
      "metadata": {
        "id": "j42oAKWHI1LY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "books.isna().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "msno.bar(books)\n",
        "# msno.heatmap(books)"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users.isna().sum()"
      ],
      "metadata": {
        "id": "6rNLBKFrNZDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "msno.bar(users)"
      ],
      "metadata": {
        "id": "jT08VD11NdPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings.isna().sum()"
      ],
      "metadata": {
        "id": "8DHPr1_VN8BE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "msno.bar(ratings)"
      ],
      "metadata": {
        "id": "5e7hXqVLOP8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Users: Contains the users. Note that the user ID's have been anonymized and map to integers. Demographic data is provided (Location,Age) is avaiable. Otherwise this field contain null values.\n",
        "\n",
        "2. Books: books are identified by there respective ISBN. Invalid ISBN's have already been removed from the dataset. Moreover some content based information is given (Book author, Book title, Year of publication, publisher) obatined from Amazon Web Services. Note that in the case of several authors, only the first is provided. URL's linking to cover images are also given, apperaing in three different flavours (Image URL-S, Image URL-L,Image URL-M).i.e. small,medium and large. This URL's point to the amazon website.\n",
        "\n",
        "3. Ratings: Contains the book ratings information. Ratings(Book rating) are either explicit, expressed on a scale from 1-10 (Higher values denoting higher appreciation), or implicit expressed by O.\n",
        "\n"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Books Dataset**"
      ],
      "metadata": {
        "id": "wGtcurPuVf1W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "books.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "\n",
        "books.describe(include='all')"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description "
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. There are around 270,000 records available in the dataset of books out of that all the records has unique ISBN number.\n",
        "2. Out of 271360 books 242,135 books has unique title and selected poems is the title used majority of the times that is 27.\n",
        "3. We have data of various books written by around 102023 various writers, out of that Agatha Christie has 632 books.\n",
        "4. We have books for around 2 centuries and out of that most of the books come from year 2002.\n",
        "5. Around 16800 unique publishers books data is stored in the dataset, Harlequin publishers have majority of the books that is around 7535 published by them."
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Users Dataset**"
      ],
      "metadata": {
        "id": "bXPEZH2qVrW8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset columns\n",
        "\n",
        "users.columns"
      ],
      "metadata": {
        "id": "sGaLYQ3RUngO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset describe\n",
        "\n",
        "users.describe(include='all')"
      ],
      "metadata": {
        "id": "K7cWvNV2Uctn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description "
      ],
      "metadata": {
        "id": "eHhW9dAaV_7B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. User id is unique id for each user.\n",
        "2. There are around 57000 various loacations to which our user belongs to, out of that London is the place to which most of our users come from.\n",
        "3. Age columns is showing, age of our users mean of age is 34 and distribution is looking positively skewed."
      ],
      "metadata": {
        "id": "R0VY0lDMU3-5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ratings Dataset**"
      ],
      "metadata": {
        "id": "rUN7KzTVV1_J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset columns\n",
        "\n",
        "ratings.columns"
      ],
      "metadata": {
        "id": "oxb50oVdVNXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset describe\n",
        "\n",
        "ratings.describe(include='all')"
      ],
      "metadata": {
        "id": "j7L6uPH0VTwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description "
      ],
      "metadata": {
        "id": "1xwazLIDWDdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ratings daatset showing ratings from 1 to 10, given by various users to different books available in the dataset. Distiribution is looking negatively skewed as our median of ratings is less than mean."
      ],
      "metadata": {
        "id": "AfykWqfEdqHe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***3. Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "users.head(3)"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_loc(tx):\n",
        "  txt = tx.split(\", \")\n",
        "  return(txt)"
      ],
      "metadata": {
        "id": "DcM0taTSiguZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_city(tx):\n",
        "  txt = tx[0]\n",
        "  return(txt)"
      ],
      "metadata": {
        "id": "V2dhM_kbmZWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_region(tx):\n",
        "  if len(tx) > 1:\n",
        "    txt = tx[1]\n",
        "  else:\n",
        "    txt = 'None'\n",
        "  return(txt)"
      ],
      "metadata": {
        "id": "AHzUZFGzjy4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_country(tx):\n",
        "  if len(tx) == 3:\n",
        "    txt = tx[2]\n",
        "  else:\n",
        "    txt = 'None'\n",
        "  return(txt)"
      ],
      "metadata": {
        "id": "CsPF_88xj8kt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users['loc'] = users[\"Location\"].apply(lambda x: split_loc(x))\n",
        "users['city'] = users[\"loc\"].apply(lambda x: split_city(x))\n",
        "users['region'] = users[\"loc\"].apply(lambda x: split_region(x))\n",
        "users['country'] = users[\"loc\"].apply(lambda x: split_country(x))"
      ],
      "metadata": {
        "id": "HVkmJg8Li_YN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users = users.drop('loc',axis=1)\n",
        "users.head(3)"
      ],
      "metadata": {
        "id": "8gkLdLpmlaUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. We have splitted location column into three different features they are city, region and country so that we could do further analysis by using them."
      ],
      "metadata": {
        "id": "l3uRtBQ4pJlZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "books.head(3)"
      ],
      "metadata": {
        "id": "IrHlySrfpguh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "books.drop(['Image-URL-S','Image-URL-M','Image-URL-L'],axis=1,inplace=True)\n",
        "books.head(3)"
      ],
      "metadata": {
        "id": "TXZmD9Avpy27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. We have dropped url columns from books dataset as we will not be considering them in further analysis."
      ],
      "metadata": {
        "id": "Ae7reMXUqJN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratings.head(4)"
      ],
      "metadata": {
        "id": "zxxZiJR_qcUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "users.head(3)"
      ],
      "metadata": {
        "id": "vCRSqRuoEVI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.core.dtypes.cast import Sized\n",
        "# Chart - 1 visualization code of bar chart\n",
        "\n",
        "def barplot_fun(size,Data,X,Y,col='deepskyblue'):\n",
        "    '''This function returns barplot for particular variable'''\n",
        "\n",
        "    plt.figure(figsize=size)\n",
        "\n",
        "    sns.set(style=\"whitegrid\", color_codes=True)\n",
        "    plots = sns.barplot(x=X, y=Y, data=Data,color=col)\n",
        "    plots.set_xticklabels(plots.get_xticklabels(), rotation=30, ha=\"right\",size=12)\n",
        "    \n",
        "    # Iterating over the bars one-by-one\n",
        "    for bar in plots.patches:\n",
        "        plots.annotate(format(bar.get_height(), '.0f'),\n",
        "                      (bar.get_x() + bar.get_width() / 2,\n",
        "                        bar.get_height()), ha='center', va='center',\n",
        "                      size=14, xytext=(0, 8),\n",
        "                      textcoords='offset points')\n",
        "    \n",
        "    # Setting the label for x-axis\n",
        "    plt.xlabel(X, size=14)\n",
        "    \n",
        "    # Setting the label for y-axis\n",
        "    plt.ylabel(Y, size=14)\n",
        "    \n",
        "    # Setting the title for the graph\n",
        "    plt.title(X+\" Distribution\",size=16)\n",
        "    \n",
        "    # Finally showing the plot\n",
        "    plt.show()\n",
        "     "
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def value_count(Data,X):\n",
        "    \n",
        "    ''' This code returns datframe with value counts'''\n",
        "\n",
        "    out = pd.DataFrame(Data[X].value_counts().reset_index())\n",
        "    out.rename(columns = {'index':X,X:'count'}, inplace = True)\n",
        "    return(out)"
      ],
      "metadata": {
        "id": "K6oc3c83HKeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Which are the countrys our users belongs to? Do analysis on the basis of locality of our users."
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "users_country = value_count(Data=users,X=\"country\")\n",
        "users_country = users_country.head(10)"
      ],
      "metadata": {
        "id": "oiK_ym6eHAgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "barplot_fun(size=(14, 6),Data=users_country,X='country',Y='count',col='blue')"
      ],
      "metadata": {
        "id": "1nDK4lW6GYww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Most of our users belongs to united states, followed by canada and then european countries such as united kingdom, germany, spain etc.\n",
        "2. Need to focus on asian and african countries also as we have very low user base in this countries."
      ],
      "metadata": {
        "id": "4kjtGCwoLegA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Which are the regions most of our users come from?"
      ],
      "metadata": {
        "id": "APXmbGrjMTF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "users_region = value_count(Data=users,X=\"region\")\n",
        "users_region = users_region.head(10)"
      ],
      "metadata": {
        "id": "3Zkx045CLdbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "barplot_fun(size=(14, 6),Data=users_region,X='region',Y='count',col='deepskyblue') "
      ],
      "metadata": {
        "id": "Vg5rfDOENGuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Most of our users belongs to devoloped regions such as california, england, ontario, texas, new york.\n",
        "2. Need to focus regions which are not much devolped or say rural in nature, need to expand connectivity so that we could reach to as many as users we can by going beyond urbanisation."
      ],
      "metadata": {
        "id": "D2NBaSnrNr-B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Show top cities with most number of book readers as per our dataset?"
      ],
      "metadata": {
        "id": "IWWd10PAOqcS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "users_city = value_count(Data=users,X=\"city\")\n",
        "users_city = users_city.head(10)"
      ],
      "metadata": {
        "id": "lmXsT5qHO-W6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "barplot_fun(size=(14, 6),Data=users_city,X='city',Y='count',col='green') "
      ],
      "metadata": {
        "id": "EIwgPor9PCDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Above graph is showing top cities to which our users come from.\n",
        "2. Uropean cities are at top in all of them."
      ],
      "metadata": {
        "id": "0LItEROzPghf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code for plotting histogram of contineous variable"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def distr(DF,x,n_bins=10):\n",
        "\n",
        "  ''' This function gives univariate distribution of contineous variable in the form of Histogram '''\n",
        "\n",
        "  legend = ['distribution']\n",
        "\n",
        "  # Creating histogram\n",
        "  fig, axs = plt.subplots(1, 1,\n",
        "                          figsize =(8,5),\n",
        "                          tight_layout = True)\n",
        "  \n",
        "  \n",
        "  # Remove axes splines\n",
        "  for s in ['top', 'bottom', 'left', 'right']:\n",
        "      axs.spines[s].set_visible(False)\n",
        "  \n",
        "  # Remove x, y ticks\n",
        "  axs.xaxis.set_ticks_position('none')\n",
        "  axs.yaxis.set_ticks_position('none')\n",
        "    \n",
        "  # Add padding between axes and labels\n",
        "  axs.xaxis.set_tick_params(pad = 5)\n",
        "  axs.yaxis.set_tick_params(pad = 10)\n",
        "  \n",
        "  # Add x, y gridlines\n",
        "  axs.grid(b = True, color ='grey',\n",
        "          linestyle ='-.', linewidth = 0.5,\n",
        "          alpha = 0.6)\n",
        "  kur = round(DF[x].kurt(),2)\n",
        "  ske = round(DF[x].skew(),2)\n",
        "  # Add Text watermark\n",
        "  fig.text(0.9, 0.75, 'Kurtosis: '+str(kur)+' & Skewness: '+str(ske),\n",
        "          fontsize = 14,\n",
        "          color ='black',\n",
        "          ha ='right',\n",
        "          va ='bottom',\n",
        "          alpha = 1.0)\n",
        "  \n",
        "  # Creating histogram\n",
        "  N, bins, patches = axs.hist(DF[x], bins = n_bins)\n",
        "  \n",
        "  # Setting color\n",
        "  fracs = ((N**(1 / 5)) / N.max())\n",
        "  norm = colors.Normalize(fracs.min(), fracs.max())\n",
        "  \n",
        "  for thisfrac, thispatch in zip(fracs, patches):\n",
        "      color = plt.cm.viridis(norm(thisfrac))\n",
        "      thispatch.set_facecolor(color)\n",
        "  \n",
        "  # Adding extra features   \n",
        "  plt.xlabel(x,size=14)\n",
        "  plt.ylabel(\"Count\",size=14)\n",
        "  plt.legend(legend)\n",
        "  plt.title('Distribution Of '+x,size=16)\n",
        "  \n",
        "  # Show plot\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "FrqSW7lCTURR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Show distribution of age of user by using histogram"
      ],
      "metadata": {
        "id": "v2m5uam6VKqK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "distr(DF=users,x='Age',n_bins=20)\n",
        "print(f'Avg. age of users : {round(users.Age.mean(),2)}')\n",
        "print(f'Median age of users : {round(users.Age.median(),2)}')"
      ],
      "metadata": {
        "id": "CCKoUjUcUoXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. With kurtosis 6.04 we could say that there is high peakedness in the data, mean is representing data very well kurtosis is highly positive. \n",
        "2. With skewness 1.18 it is clearly showing positively skewed distribution, most of the users age lies between 24-40 which is clearly showing that we have established good connectivity with youth."
      ],
      "metadata": {
        "id": "ViIkyeOEWAjI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "books.head(3)"
      ],
      "metadata": {
        "id": "fDTS6Cu8Y3zP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Which book titles are repeatatively used by authors? Which book titles are showing different book series?"
      ],
      "metadata": {
        "id": "IDFQcM3Sa8c7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "books_title = value_count(Data=books,X=\"Book-Title\")\n",
        "books_title = books_title.head(10) "
      ],
      "metadata": {
        "id": "pBAttZKqbUuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "barplot_fun(size=(14, 6),Data=books_title,X='Book-Title',Y='count',col='brown')"
      ],
      "metadata": {
        "id": "o2xXaLCBboEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Above books belongs to different book series or we could say above are few of the book series of which information is available in the dataset."
      ],
      "metadata": {
        "id": "YqsO882Ocez-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Number of books published w.r.t year as per available dataset."
      ],
      "metadata": {
        "id": "jFRILMNcdjsz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "books_year = pd.DataFrame(books['Year-Of-Publication'].value_counts())\n",
        "books_year.drop(['DK Publishing Inc','Gallimard'],axis=0,inplace=True)\n",
        "books_year = books_year.reset_index()\n",
        "books_year.rename(columns = {'index':'Year','Year-Of-Publication':'count'}, inplace = True)\n",
        "books_year['Year'] = books_year['Year'].astype(int)\n",
        "books_year.sort_values(by='Year',inplace=True)\n",
        "books_year.reset_index(inplace=True)\n",
        "books_year.drop('index',axis=1,inplace=True)\n",
        "books_year = books_year.iloc[6:,0:]\n",
        "books_year.head(5)"
      ],
      "metadata": {
        "id": "gEFGSTL0d8NG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = books_year['Year']\n",
        "y = books_year['count']\n",
        "\n",
        "plt.figure(figsize=(14, 4))\n",
        "\n",
        "\n",
        "plt.plot(x,y,color='red')\n",
        "plt.xlabel(\"Year\",size=14)  # add X-axis label\n",
        "plt.ylabel(\"Total books published\",size=14)  # add Y-axis label\n",
        "plt.title(\"Books published per year\",size=16)  # add title\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o32syA3BkIEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. As we could see in above graph, from 1900 to 1960 published books with respect to years were very low in number as per available dataset.\n",
        "2. From 1970 onwards to 2000 trend in books publication is increased and ample amount of books that are published in this time span are available in the dataset.\n",
        "3. From 2010 onwards again this number has reduced as per the information that we have got.\n",
        "4. We could simply conclude that in our dataset, we have information about the books which are published in the timespan of 1975 to 2005."
      ],
      "metadata": {
        "id": "CX3BMrF4mSuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Authors with most number of books as per available dataset."
      ],
      "metadata": {
        "id": "a4II1LqK3MO6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "books_author = value_count(Data=books,X=\"Book-Author\")\n",
        "books_author = books_author.head(10) "
      ],
      "metadata": {
        "id": "R4M_ddaw5GcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "barplot_fun(size=(14, 6),Data=books_author,X='Book-Author',Y='count',col='lightgreen')"
      ],
      "metadata": {
        "id": "PLnApJEE5WJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Above are few of the authors, which has most number of books published as per available dataset."
      ],
      "metadata": {
        "id": "545Apsr45733"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Top publishers in the dataset."
      ],
      "metadata": {
        "id": "IzmhdKqn7lBW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "books_publisher = value_count(Data=books,X=\"Publisher\")\n",
        "books_publisher = books_publisher.head(10) "
      ],
      "metadata": {
        "id": "10aGY-7475J2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "barplot_fun(size=(14, 6),Data=books_publisher,X='Publisher',Y='count',col='darkorange')"
      ],
      "metadata": {
        "id": "deW9z3Vo8Lba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Above are few of the publishers, which has most number of books published as per available dataset."
      ],
      "metadata": {
        "id": "o3t9vCAF8mx9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Show distribution of book ratings."
      ],
      "metadata": {
        "id": "yn5i4zrCB14M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "distr(DF=ratings,x='Book-Rating',n_bins=10)\n",
        "print(f'Avg. book-rating : {round(ratings[\"Book-Rating\"].mean(),2)}')\n",
        "print(f'Median of book-rating : {round(ratings[\"Book-Rating\"].median(),2)}')"
      ],
      "metadata": {
        "id": "UO625GtwDEgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. With kurtosis -1.24 we could say that there is no any peakedness in the data, mean is definately not representing data, distribution is platykurtic. \n",
        "2. With skewness 0.73 it is clearly showing slightly positively skewed distribution median is very low than mean of book-rating, 50 % of the peoples has given 0 rating to most of the books."
      ],
      "metadata": {
        "id": "SEoAkw_mEdFz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Top books as per rating."
      ],
      "metadata": {
        "id": "qFKEztP2F_i4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratings.head(5)"
      ],
      "metadata": {
        "id": "SeV9GdiDB7cT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_book_rating = pd.DataFrame(ratings.groupby('ISBN')['Book-Rating'].mean())\n",
        "top_book_rating = top_book_rating.reset_index()\n",
        "top_book_rating.rename(columns = {'index':'ISBN'}, inplace = True)\n",
        "top_book_rating.sort_values(by='Book-Rating',ascending=False,inplace=True)\n",
        "top_book_rating.reset_index(inplace=True)\n",
        "top_book_rating.drop('index',axis=1,inplace=True)\n",
        "top_book_rating "
      ],
      "metadata": {
        "id": "Z9j7E3_FF4VZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In above dataframe we are getting average ratings for various books available in the dataset w.r.t there ISBN numbers."
      ],
      "metadata": {
        "id": "cPwByi86ISIM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Join operation on two different dataframes to get names of books on the basis of ISBN numbers\n",
        "\n",
        "books_rating_new = pd.merge(top_book_rating,books, how='inner', on = 'ISBN')\n",
        "books_rating_new = books_rating_new.iloc[:,0:3]\n",
        "books_rating_new.head(4)"
      ],
      "metadata": {
        "id": "AK9cIHYmNyN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comment_words = ''\n",
        "for val in books_rating_new['Book-Title']:\n",
        "     \n",
        "    # typecaste each val to string\n",
        "    val = str(val)\n",
        " \n",
        "    # split the value\n",
        "    tokens = val.split()\n",
        "     \n",
        "    # Converts each token into lowercase\n",
        "    for i in range(len(tokens)):\n",
        "        tokens[i] = tokens[i].lower()\n",
        "     \n",
        "    comment_words += \"_\".join(tokens)+\" \""
      ],
      "metadata": {
        "id": "KHInKyqhgai7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = set(STOPWORDS)\n",
        "\n",
        "wordcloud = WordCloud(width = 900, height = 450,\n",
        "                background_color ='white',\n",
        "                stopwords = stopwords,\n",
        "                min_font_size = 10).generate(comment_words)\n",
        " \n",
        "# plot the WordCloud image                      \n",
        "plt.figure(figsize = (8, 8), facecolor = None)\n",
        "plt.imshow(wordcloud)\n",
        "plt.axis(\"off\")\n",
        "plt.tight_layout(pad = 0)\n",
        " \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "j3S5j0f8imYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "books.head(3)"
      ],
      "metadata": {
        "id": "PYwBzCsah1no"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 11. What are the top author-publisher combinations?"
      ],
      "metadata": {
        "id": "lq-unDVNjHrg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def concat_str(st1,st2):\n",
        "  '''This function concatenet two strings'''\n",
        "  out = st1+' '+st2\n",
        "  return(out)"
      ],
      "metadata": {
        "id": "ljw_JJuAmNYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_author_publisher = pd.DataFrame(books.groupby(by=['Publisher','Book-Author'])['Book-Title'].count())\n",
        "top_author_publisher.reset_index(inplace=True)\n",
        "top_author_publisher.sort_values(by='Book-Title',ascending=False,inplace=True)\n",
        "top_author_publisher['Author_Publisher'] = top_author_publisher['Book-Author'].map(str) + '-' + top_author_publisher['Publisher'].map(str)\n",
        "top_author_publisher = top_author_publisher.head(15)\n",
        "top_author_publisher"
      ],
      "metadata": {
        "id": "sa4Nr-WEi4x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "barplot_fun(size=(14, 6),Data=top_author_publisher,X='Author_Publisher',Y='Book-Title',col='darkred')"
      ],
      "metadata": {
        "id": "HsYXH2uupR2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Let's create one final dataframe by combining above three different dataframes so that we could get, some more information about variables by establishing relationship in between them."
      ],
      "metadata": {
        "id": "eoCfoNtfrWG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.merge(ratings,books, how='inner', on = 'ISBN')\n",
        "df2 = pd.merge(df1,users, how='inner', on = 'User-ID')\n",
        "df = df2.copy()"
      ],
      "metadata": {
        "id": "iT-zv_fMqD8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(3)"
      ],
      "metadata": {
        "id": "Hxy-HsmZspPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create one column to distribute ratings in four categories bad,mediam,good,best."
      ],
      "metadata": {
        "id": "Bn51q6gZzEuO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new = []\n",
        "for i in df['Book-Rating']:\n",
        "  if i<=3:\n",
        "    new.append('bad')\n",
        "  elif i<=6:\n",
        "    new.append('medium')\n",
        "  elif i<=8:\n",
        "    new.append('good')\n",
        "  else:\n",
        "    new.append('very_good')\n",
        "len(new)"
      ],
      "metadata": {
        "id": "uuAn8Vq2zCX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Book_Rating_Cat\"] = new"
      ],
      "metadata": {
        "id": "SM2g7jA70Zes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 12. Is there any relation between Age of users and ratings given by them??"
      ],
      "metadata": {
        "id": "VO7P-DBkuLPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Scatter(X,Y):\n",
        "  '''This function gives scatter plot of two contineous variables'''\n",
        "\n",
        "  x = df[X]\n",
        "  y = df[Y]\n",
        "  colors = df[Y]\n",
        "  sizes = df[Y]\n",
        "\n",
        "  plt.figure(figsize = (10, 6))\n",
        "  plt.ticklabel_format(style = 'plain')\n",
        "  plt.scatter(x, y, c = colors, s = sizes, alpha = 0.3, cmap = 'PRGn') #viridis\n",
        "  plt.colorbar()\n",
        "\n",
        "  # cor = df[x,y].corr()\n",
        "\n",
        "  # fig.text(0.9, 0.75, 'Correlation: '+str(cor),fontsize = 14,color ='black',ha ='right',va ='bottom',alpha = 1.0)\n",
        "  \n",
        "  plt.xlabel(X,size=14)\n",
        "  plt.ylabel(Y,size=14)\n",
        "  plt.title(X+\" vs \"+Y,size=16);"
      ],
      "metadata": {
        "id": "Ltan0Du5ucgn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Scatter(X='Age',Y='Book-Rating')"
      ],
      "metadata": {
        "id": "YDttrcItutp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Peoples with more age are giving honest reviews as compared to the young peoples. We could see that thing from the density of our data points available in above graph.\n",
        "2. Either books are getting very good reviews, they are in the range of 8-10 or very bad reviews in the range of 1-4.\n",
        "3. Peoples with age more than 50 years are genrally giving good reviews."
      ],
      "metadata": {
        "id": "-9wn26nZwdmm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 13. Distribution of book-ratings pie-chart."
      ],
      "metadata": {
        "id": "mBWCmCG80qCy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "books_ratng = value_count(Data=df,X=\"Book_Rating_Cat\")\n",
        "books_ratng"
      ],
      "metadata": {
        "id": "7rdzdZO11jHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Pie Chart\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "data = books_ratng['count']\n",
        "keys = books_ratng['Book_Rating_Cat']\n",
        "  \n",
        "# declaring exploding pie\n",
        "explode = [0.01,0.03,0.05,0.07]\n",
        "# define Seaborn color palette to use\n",
        "palette_color = sns.color_palette('Dark2')\n",
        "  \n",
        "# plotting data on chart\n",
        "plt.pie(data, labels=['bad','good','very_good','medium'], colors=palette_color,explode=explode,autopct='%.0f%%',textprops={'fontsize': 14})\n",
        "\n",
        "\n",
        "plt.legend(fontsize=14)\n",
        "\n",
        "plt.title(\"Book Rating Distribution\",size=16)\n",
        "# displaying chart\n",
        "plt.show() "
      ],
      "metadata": {
        "id": "rBQKpjNG0iaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 14. Is there any outliers present in the Age column??"
      ],
      "metadata": {
        "id": "v5Ii2AyedGa4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def outlier_per(df,x):\n",
        "\n",
        "  '''this function gives number of outliers present in the feature by using IQR method'''\n",
        "\n",
        "  q1 = df[x].quantile(0.25)\n",
        "  q3 = df[x].quantile(0.75)\n",
        "  iqr = q3-q1\n",
        "  lw = q1 - (1.5*iqr)\n",
        "  uw = q3 + (1.5*iqr)\n",
        "\n",
        "  cnt = 0\n",
        "  for i in df[x]:\n",
        "    if (i>uw):\n",
        "      cnt+=1\n",
        "    elif(i<lw):\n",
        "      cnt+=1\n",
        "  strng = f'{round(cnt*100/len(df),2)} % Outliers present in column {x} in number it is {cnt}'\n",
        "  strng2 = f'mean: {round(df[x].mean(),2)}'\n",
        "  strng3 = f'median: {round(df[x].median(),2)}'\n",
        "  strng4 = f'minimum: {round(df[x].min(),2)}'\n",
        "  strng5 = f'maximum: {round(df[x].max(),2)}'\n",
        "  strng6 = f'kurtosis: {round(df[x].kurt(),2)}'\n",
        "  strng7 = f'skewness: {round(df[x].skew(),2)}'\n",
        "  \n",
        "  return(strng,strng2,strng3,strng4,strng5,strng6,strng7)"
      ],
      "metadata": {
        "id": "YWo7EfXIeECO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "sns.boxplot(df['Age'])\n",
        "plt.title('Boxplot of Age',size=16)\n",
        "outlier_per(df=df,x='Age')"
      ],
      "metadata": {
        "id": "D0oBrUghfssh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 15. Correlation heatmap of contineous variables in dataframe"
      ],
      "metadata": {
        "id": "oPc3_HZvjd5-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new = []\n",
        "for i in df['Year-Of-Publication']:\n",
        "  if i in ['DK Publishing Inc','Gallimard']:\n",
        "    new.append(0)\n",
        "  else:\n",
        "    new.append(int(i))\n",
        "df['Year-Of-Publication2'] = new\n",
        "df['Year-Of-Publication2'].dtype"
      ],
      "metadata": {
        "id": "Jmljqxo5ZdeN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop('Year-Of-Publication',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "SWclEryIckFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "df['country_encoded'] = le.fit_transform(df['country'])"
      ],
      "metadata": {
        "id": "8_iuyKUwj2n3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (15,7))\n",
        "colormap = plt.cm.plasma\n",
        "sns.heatmap(df.corr(),cmap = colormap,annot=True);\n",
        "sns.set(font_scale=1.1)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "egVunge-ctk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we could see in above heatmap, almost all the variables are independant of each other and they dont posess any kind of correlation in between them."
      ],
      "metadata": {
        "id": "EBiA9SkAlNUA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Peoples whom gave either good or very good rating to the books are older as compared to the peoples whom gave bad rating to the books."
      ],
      "metadata": {
        "id": "6bzDGgA-Lf29"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "H0: Mean age of peoples with good rating> Mean age of peoples with bad ratings\n",
        "\n",
        "H1: Mean age of peoples with good rating<= Mean age of peoples with bad ratings"
      ],
      "metadata": {
        "id": "3FOH6A2MMVGV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we have to compare mean of two distributions one for books with good rating and another for book with bad rating, we will be performing t-test in this case and we will use p-value approch to do testing for statistical significance. "
      ],
      "metadata": {
        "id": "DTOs42CiMkRd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, Let's form two different distributions one for good ratings and another for bad ratings by using above dataframe."
      ],
      "metadata": {
        "id": "5AcqCaviNSjm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_bad = df[df['Book_Rating_Cat']=='bad']\n",
        "df_good = df[(df['Book_Rating_Cat']=='very_good')]\n",
        "dfb_age = df_bad['Age']\n",
        "dfg_age = df_good['Age']\n",
        "dfb_age = [x for x in dfb_age if x>=0]\n",
        "dfg_age = [x for x in dfg_age if x>=0]"
      ],
      "metadata": {
        "id": "tOoX_iNzMjaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import ttest_ind  \n",
        "    \n",
        "def t_test(x,y,alternative='both-sided'):\n",
        "        _, double_p = ttest_ind(x,y,equal_var = False)\n",
        "        if alternative == 'both-sided':\n",
        "            pval = double_p\n",
        "        elif alternative == 'greater':\n",
        "            if np.mean(x) > np.mean(y):\n",
        "                 pval = double_p/2.\n",
        "            else:\n",
        "                 pval = 1.0 - double_p/2.\n",
        "        elif alternative == 'less':\n",
        "            if np.mean(x) < np.mean(y):\n",
        "                 pval = double_p/2.\n",
        "            else:\n",
        "              pval = 1.0 - double_p/2.\n",
        "\n",
        "        op = 'Hence we are failed to reject null hypothesis (H0) for significane level 0.05'\n",
        "        if pval < 0.05:\n",
        "          op = 'Hence we are rejecting null hypothesis (H0) for significane level 0.05 '\n",
        "        return (f'P-Value: {pval}, {op}')"
      ],
      "metadata": {
        "id": "h2dzcb0VQQlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t_test(x=dfb_age,y=dfg_age,alternative='greater')"
      ],
      "metadata": {
        "id": "mWE5TVukQTov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hence from above test we could say that mean age of peoples with good rating is either less or equal to mean age of peoples with bad rating."
      ],
      "metadata": {
        "id": "w2i4XpybRH4I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Book_Rating_Cat_Encoded'] = le.fit_transform(df['Book_Rating_Cat'])\n",
        "df.head(3)"
      ],
      "metadata": {
        "id": "MJ7NBCadUUAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ratings of peoples are changing with change in there location. That means geographical location of a person is also affecting the ratings given by them."
      ],
      "metadata": {
        "id": "TGAecLy-UsWW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "H0: There is relationship between country column and ratings.\n",
        "\n",
        "H1: There is no relationship between country column and ratings."
      ],
      "metadata": {
        "id": "ZpEnIyZfVBko"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we are analysing two categorical variables, here We are going to use chi-squre test of independance."
      ],
      "metadata": {
        "id": "phhzdJFVVU9K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new = pd.crosstab(df['country_encoded'],df['Book_Rating_Cat_Encoded'])\n",
        "new = pd.DataFrame(new)\n",
        "new.reset_index(inplace=True)\n",
        "new['Total'] = new[0] + new[1] + new[2] + new[3]\n",
        "new = new.iloc[1:,:]\n",
        "new.set_index('country_encoded',inplace=True)\n",
        "new.loc['Total'] = new.iloc[:, :].sum()\n",
        "new"
      ],
      "metadata": {
        "id": "nBL5R_KIVllW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# significance level\n",
        "alpha = 0.05\n",
        "\n",
        "# Calcualtion of Chisquare\n",
        "chi_square = 0\n",
        "rows = new.index.unique()\n",
        "columns = new.columns.unique()\n",
        "for i in columns:\n",
        "    for j in rows:\n",
        "        O = new[i][j]\n",
        "        E = new[i]['Total'] * new['Total'][j] / new['Total']['Total']\n",
        "        chi_square += (O-E)**2/E"
      ],
      "metadata": {
        "id": "yqAniTDpX4LZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The p-value approach\n",
        "print(\"Approach 1: The p-value approach to hypothesis testing in the decision rule\")\n",
        "p_value = 1 - stats.chi2.cdf(chi_square, (len(rows)-1)*(len(columns)-1))\n",
        "conclusion = \"Failed to reject the null hypothesis.\"\n",
        "if p_value <= alpha:\n",
        "    conclusion = \"Null Hypothesis is rejected.\"\n",
        "        \n",
        "print(\"chisquare-score is:\", chi_square, \" and p value is:\", p_value)\n",
        "print(conclusion)"
      ],
      "metadata": {
        "id": "GMZR2ZkqX8o1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hence from conclusion of above test we could say that there is no relationship in between geographical location and ratings given by peoples."
      ],
      "metadata": {
        "id": "Wu5agD79YqNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(3)"
      ],
      "metadata": {
        "id": "VS5d-1aaqaDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Time span in which books were published affecting ratings given by users."
      ],
      "metadata": {
        "id": "_Is6vuT-sHX9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "H0: There is relationship between ratings column and time span.\n",
        "\n",
        "H1: There is no relationship between ratings column and time span."
      ],
      "metadata": {
        "id": "xrurIHARse8X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we are analysing two categorical variables, here We are going to use chi-squre test of independance."
      ],
      "metadata": {
        "id": "g3ebS9gbsv-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new = []\n",
        "for i in df['Year-Of-Publication2']:\n",
        "  if i <= 1990:\n",
        "    new.append(\"before_90's\")\n",
        "  elif i <= 1995:\n",
        "    new.append(\"90_95\")\n",
        "  elif i <= 2000:\n",
        "    new.append(\"95_2000\")\n",
        "  else:\n",
        "    new.append(\"after_2000\")\n",
        "  \n",
        "df[\"time_span\"] = new"
      ],
      "metadata": {
        "id": "PDrDcg09sz9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new = pd.crosstab(df['time_span'],df['Book_Rating_Cat_Encoded'])\n",
        "new = pd.DataFrame(new)\n",
        "new.reset_index(inplace=True)\n",
        "new['Total'] = new[0] + new[1] + new[2] + new[3]\n",
        "new = new.iloc[1:,:]\n",
        "new.set_index('time_span',inplace=True)\n",
        "new.loc['Total'] = new.iloc[:, :].sum()\n",
        "new"
      ],
      "metadata": {
        "id": "2ycMj_zXupmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# significance level\n",
        "alpha = 0.05\n",
        "\n",
        "# Calcualtion of Chisquare\n",
        "chi_square = 0\n",
        "rows = new.index.unique()\n",
        "columns = new.columns.unique()\n",
        "for i in columns:\n",
        "    for j in rows:\n",
        "        O = new[i][j]\n",
        "        E = new[i]['Total'] * new['Total'][j] / new['Total']['Total']\n",
        "        chi_square += (O-E)**2/E"
      ],
      "metadata": {
        "id": "6sPq0JN8vBpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The p-value approach\n",
        "print(\"Approach 1: The p-value approach to hypothesis testing in the decision rule\")\n",
        "p_value = 1 - stats.chi2.cdf(chi_square, (len(rows)-1)*(len(columns)-1))\n",
        "conclusion = \"Failed to reject the null hypothesis.\"\n",
        "if p_value <= alpha:\n",
        "    conclusion = \"Null Hypothesis is rejected.\"\n",
        "        \n",
        "print(\"chisquare-score is:\", chi_square, \" and p value is:\", p_value)\n",
        "print(conclusion)"
      ],
      "metadata": {
        "id": "t8erT0kdvGik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hence from conclusion of above test we could say that there is no relationship in between time_span of book published and ratings given by peoples."
      ],
      "metadata": {
        "id": "IFG4TcvXvQCt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "\n",
        "'''We have around 35% null values in Age column so we are going to replace them with mean \n",
        "value of Age coulmn as we have seen above, by doing hypothesis testing that ratings are not getting \n",
        "affected due to age, so we can replace them with mean of that column''' #37.39764848314286\n",
        "\n",
        "df['Age'] = df['Age'].fillna(37)"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''In book-author column and publisher column there are only 3 null values present so we are going\n",
        "to drop them directly as they are not considerable in number in such a huge dataset with more than 10,00,000 \n",
        "records'''\n",
        "\n",
        "df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "9DolYiETh0XV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' We have removed all the missing values present in our dataset by using different methods\n",
        "for different columns which are mentioned above'''\n",
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "vyInc94dhiJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "\n",
        "''' As we have only one contineous column which is age and we have already checked \n",
        "around 6.70% outliers are present in the age column so we are going to replace values \n",
        "which are greater than 95 by using upper whisker value and values lower than 10 \n",
        "by using lw'''\n"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def outlier_detection(df,x):\n",
        "\n",
        "  '''this function gives lower whicker and upper whisker of the feature by using IQR method'''\n",
        "\n",
        "  q1 = df[x].quantile(0.25)\n",
        "  q3 = df[x].quantile(0.75)\n",
        "  iqr = q3-q1\n",
        "  lw = q1 - (1.5*iqr)\n",
        "  uw = q3 + (1.5*iqr)\n",
        "  return(lw,uw)"
      ],
      "metadata": {
        "id": "yWpd7KFIj1s2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def outlier_replace(df,x):\n",
        "\n",
        "  '''this function replaces outliers lower than lower whisker with lower whicker and outliers higher than upper whisker with upper whicker'''\n",
        "\n",
        "  lw,uw = outlier_detection(df,x)\n",
        "  lstn = []\n",
        "  for i in df[x]:\n",
        "    if (i<10):\n",
        "      lstn.append(uw)\n",
        "    elif (i>95):\n",
        "      lstn.append(uw)\n",
        "    else:\n",
        "      lstn.append(i)\n",
        "  df[x+'_out_replace'] = lstn"
      ],
      "metadata": {
        "id": "6FfMygoojwSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outlier_replace(df=df,x='Age')"
      ],
      "metadata": {
        "id": "fxTu_odQkQoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def boxplot_out(df,X,Y):\n",
        "\n",
        "    '''this function gives boxplot of variables with and without outliers'''\n",
        "\n",
        "    ## detecting outliers and calculating there %\n",
        "\n",
        "    strng0 = f'Boxplot of {X}'\n",
        "    strng = outlier_per(df,X)[0]\n",
        "    strng2 = outlier_per(df,X)[1]\n",
        "    strng3 = outlier_per(df,X)[2]\n",
        "    strng4 = outlier_per(df,X)[3]\n",
        "    strng5 = outlier_per(df,X)[4]\n",
        "    strng6 = outlier_per(df,X)[5]\n",
        "    strng7 = outlier_per(df,X)[6]\n",
        "    \n",
        "\n",
        "    ## plotting figure\n",
        "    fig, axes = plt.subplots(1,2, figsize=(22,6))\n",
        "    sns.boxplot(ax=axes[0], data=df,x=X)\n",
        "\n",
        "    ##labels\n",
        "\n",
        "    fig.text(0.35, 0.9,strng0,fontsize = 16,color ='black',ha ='right',va ='bottom',alpha = 1.0)\n",
        "    fig.text(0.45, 0.75,strng,fontsize = 12,color ='black',ha ='right',va ='bottom',alpha = 1.0)\n",
        "    fig.text(0.45, 0.70,strng2,fontsize = 12,color ='black',ha ='right',va ='bottom',alpha = 1.0)\n",
        "    fig.text(0.45, 0.65,strng3,fontsize = 12,color ='black',ha ='right',va ='bottom',alpha = 1.0)\n",
        "    fig.text(0.45, 0.60,strng4,fontsize = 12,color ='black',ha ='right',va ='bottom',alpha = 1.0)\n",
        "    fig.text(0.45, 0.55,strng5,fontsize = 12,color ='black',ha ='right',va ='bottom',alpha = 1.0)\n",
        "    fig.text(0.45, 0.50,strng6,fontsize = 12,color ='black',ha ='right',va ='bottom',alpha = 1.0)\n",
        "    fig.text(0.45, 0.45,strng7,fontsize = 12,color ='black',ha ='right',va ='bottom',alpha = 1.0)\n",
        "\n",
        "    strng0 = f'Boxplot of {Y}'\n",
        "    strng = outlier_per(df,Y)[0]\n",
        "    strng2 = outlier_per(df,Y)[1]\n",
        "    strng3 = outlier_per(df,Y)[2]\n",
        "    strng4 = outlier_per(df,Y)[3]\n",
        "    strng5 = outlier_per(df,Y)[4]\n",
        "    strng6 = outlier_per(df,Y)[5]\n",
        "    strng7 = outlier_per(df,Y)[6]\n",
        "    \n",
        "\n",
        "    ## plotting figure\n",
        "    # fig, axes = plt.subplots(1,2, figsize=(22,6))\n",
        "    sns.boxplot(ax=axes[1], data=df,x=Y)\n",
        "\n",
        "    ##labels\n",
        "    # plt.title(f'Boxplot of {Y}',size=14)\n",
        "\n",
        "    fig.text(0.80, 0.9,strng0,fontsize = 16,color ='black',ha ='right',va ='bottom',alpha = 1.0)\n",
        "    fig.text(0.85, 0.75,strng,fontsize = 12,color ='black',ha ='right',va ='bottom',alpha = 1.0)\n",
        "    fig.text(0.85, 0.70,strng2,fontsize = 12,color ='black',ha ='right',va ='bottom',alpha = 1.0)\n",
        "    fig.text(0.85, 0.65,strng3,fontsize = 12,color ='black',ha ='right',va ='bottom',alpha = 1.0)\n",
        "    fig.text(0.85, 0.60,strng4,fontsize = 12,color ='black',ha ='right',va ='bottom',alpha = 1.0)\n",
        "    fig.text(0.85, 0.55,strng5,fontsize = 12,color ='black',ha ='right',va ='bottom',alpha = 1.0)\n",
        "    fig.text(0.85, 0.50,strng6,fontsize = 12,color ='black',ha ='right',va ='bottom',alpha = 1.0)\n",
        "    fig.text(0.85, 0.45,strng7,fontsize = 12,color ='black',ha ='right',va ='bottom',alpha = 1.0)\n",
        "    \n",
        "    # show plot\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "vH8DwLXOkUsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "boxplot_out(df=df,X='Age',Y='Age_out_replace')"
      ],
      "metadata": {
        "id": "usqoIWcYkmTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns\n",
        "df.drop(['Location','Age','Book_Rating_Cat','time_span','country'],axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8AllZl9iqZo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely."
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why? "
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the conclusion here."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}